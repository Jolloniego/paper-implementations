# Paper-Implementations

Minimalist implementation of Deep Learning research papers in Jupyter notebook format for easy viewing. All papers were implemented in Colab (due to GPU availability) and can be opened directly with no google account required. 

The goal of the repo is to provide simple and self-contained implemantations of different papers, allowing model creation, training and inference from Google Colab in reasonable time. This some times means using different data to avoid computation and memory limits but the code could be used on any dataset when given enough resources.

***

### 1) Simple GAN - [__[Paper]__](https://arxiv.org/abs/1406.2661) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/GAN.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/GAN.ipynb)

### 2) Auxiliary Classifier GAN - [__[Paper]__](https://arxiv.org/abs/1610.09585.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/AC_GAN.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/AC_GAN.ipynb)

### 3) Pix2Pix GAN - [__[Paper]__](https://arxiv.org/abs/1611.07004) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/Pix2Pix_GAN.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/Pix2Pix_GAN.ipynb)

### 4) UNet Semantic Segmentation - [__[Paper]__](https://arxiv.org/abs/1505.04597) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/UNet_Segmentation.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/UNet_Segmentation.ipynb)

### 5) Twin Auxiliary Classifier GAN - [__[Paper]__](https://arxiv.org/abs/1907.02690.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/TAC_GAN.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/TAC_GAN.ipynb)

### 6) Barlow Twins - [__[Paper]__](https://arxiv.org/abs/2103.03230.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/Barlow_Twins.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/Barlow_Twins.ipynb)

### 7) FCN Semantic Segmentation - [__[Paper]__](https://arxiv.org/abs/1411.4038.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/FCNet_Segmentation.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/FCNet_Segmentation.ipynb)

### 8) Vision Transformer for classification - [__[Paper]__](https://arxiv.org/abs/2010.11929.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/ViT_Scenes.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/ViT_Scenes.ipynb)

### 9) EfficientNets for classification - [__[Paper]__](https://arxiv.org/abs/1905.11946.pdf) -  [__[Code]__](https://github.com/Jolloniego/paper-implementations/blob/main/notebooks/EfficientNets.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jolloniego/paper-implementations/blob/main/notebooks/EfficientNets.ipynb)


